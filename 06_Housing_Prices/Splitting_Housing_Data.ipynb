{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T21:30:51.285110Z",
     "start_time": "2021-01-22T21:30:42.271058Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://192.168.2.10:4041\n",
       "SparkContext available as 'sc' (version = 3.0.0, master = local[*], app id = local-1611351045065)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "init: Int = 1\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val init = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T21:30:55.676255Z",
     "start_time": "2021-01-22T21:30:51.286979Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
      "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|ocean_proximity|\n",
      "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
      "|  -122.23|   37.88|              41.0|      880.0|         129.0|     322.0|     126.0|       8.3252|          452600.0|       NEAR BAY|\n",
      "|  -122.22|   37.86|              21.0|     7099.0|        1106.0|    2401.0|    1138.0|       8.3014|          358500.0|       NEAR BAY|\n",
      "|  -122.24|   37.85|              52.0|     1467.0|         190.0|     496.0|     177.0|       7.2574|          352100.0|       NEAR BAY|\n",
      "|  -122.25|   37.85|              52.0|     1274.0|         235.0|     558.0|     219.0|       5.6431|          341300.0|       NEAR BAY|\n",
      "|  -122.25|   37.85|              52.0|     1627.0|         280.0|     565.0|     259.0|       3.8462|          342200.0|       NEAR BAY|\n",
      "|  -122.25|   37.85|              52.0|      919.0|         213.0|     413.0|     193.0|       4.0368|          269700.0|       NEAR BAY|\n",
      "|  -122.25|   37.84|              52.0|     2535.0|         489.0|    1094.0|     514.0|       3.6591|          299200.0|       NEAR BAY|\n",
      "|  -122.25|   37.84|              52.0|     3104.0|         687.0|    1157.0|     647.0|         3.12|          241400.0|       NEAR BAY|\n",
      "|  -122.26|   37.84|              42.0|     2555.0|         665.0|    1206.0|     595.0|       2.0804|          226700.0|       NEAR BAY|\n",
      "|  -122.25|   37.84|              52.0|     3549.0|         707.0|    1551.0|     714.0|       3.6912|          261100.0|       NEAR BAY|\n",
      "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "housing: org.apache.spark.sql.DataFrame = [longitude: double, latitude: double ... 8 more fields]\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val housing = spark.read.format(\"csv\")\n",
    "    .option(\"header\",\"true\")\n",
    "    .option(\"inferSchema\",\"true\")\n",
    "    .load(\"housing.csv\")\n",
    "housing.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T21:30:57.661355Z",
     "start_time": "2021-01-22T21:30:55.678799Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-----------------+------------------+------------------+------------------+------------------+-----------------+------------------+------------------+---------------+\n",
      "|summary|          longitude|         latitude|housing_median_age|       total_rooms|    total_bedrooms|        population|       households|     median_income|median_house_value|ocean_proximity|\n",
      "+-------+-------------------+-----------------+------------------+------------------+------------------+------------------+-----------------+------------------+------------------+---------------+\n",
      "|  count|              20640|            20640|             20640|             20640|             20433|             20640|            20640|             20640|             20640|          20640|\n",
      "|   mean|-119.56970445736148| 35.6318614341087|28.639486434108527|2635.7630813953488| 537.8705525375618|1425.4767441860465|499.5396802325581|3.8706710029070246|206855.81690891474|           null|\n",
      "| stddev|  2.003531723502584|2.135952397457101| 12.58555761211163|2181.6152515827944|421.38507007403115|  1132.46212176534|382.3297528316098| 1.899821717945263|115395.61587441359|           null|\n",
      "|    min|            -124.35|            32.54|               1.0|               2.0|               1.0|               3.0|              1.0|            0.4999|           14999.0|      <1H OCEAN|\n",
      "|    max|            -114.31|            41.95|              52.0|           39320.0|            6445.0|           35682.0|           6082.0|           15.0001|          500001.0|     NEAR OCEAN|\n",
      "+-------+-------------------+-----------------+------------------+------------------+------------------+------------------+-----------------+------------------+------------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "housing.describe().show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting using random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T21:30:58.708574Z",
     "start_time": "2021-01-22T21:30:57.663069Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|summary|          longitude|\n",
      "+-------+-------------------+\n",
      "|  count|              16563|\n",
      "|   mean|-119.57226951639137|\n",
      "| stddev|  2.006840716149941|\n",
      "|    min|            -124.35|\n",
      "|    max|            -114.49|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "train1: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [longitude: double, latitude: double ... 8 more fields]\n",
       "test1: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [longitude: double, latitude: double ... 8 more fields]\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val Array(train1, test1) = housing\n",
    "    .randomSplit(Array(0.8, 0.2))\n",
    "\n",
    "train1.select(\"longitude\")\n",
    "    .describe()\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T21:30:59.394821Z",
     "start_time": "2021-01-22T21:30:58.715040Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|summary|          longitude|\n",
      "+-------+-------------------+\n",
      "|  count|              16504|\n",
      "|   mean|-119.58617123121586|\n",
      "| stddev| 2.0080906727637027|\n",
      "|    min|            -124.35|\n",
      "|    max|            -114.31|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "train2: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [longitude: double, latitude: double ... 8 more fields]\n",
       "test2: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [longitude: double, latitude: double ... 8 more fields]\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val Array(train2, test2) = housing\n",
    "    .randomSplit(Array(0.8, 0.2))\n",
    "\n",
    "train2.select(\"longitude\")\n",
    "    .describe()\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T14:25:00.339282Z",
     "start_time": "2021-01-21T14:25:00.079743Z"
    }
   },
   "source": [
    "# Spliting using random and same seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T21:30:59.985844Z",
     "start_time": "2021-01-22T21:30:59.396651Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|summary|          longitude|\n",
      "+-------+-------------------+\n",
      "|  count|              16510|\n",
      "|   mean|-119.56390490611753|\n",
      "| stddev| 2.0075057468016757|\n",
      "|    min|            -124.35|\n",
      "|    max|            -114.31|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "train3: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [longitude: double, latitude: double ... 8 more fields]\n",
       "test3: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [longitude: double, latitude: double ... 8 more fields]\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val Array(train3, test3) = housing\n",
    "    .randomSplit(Array(0.8, 0.2), 47)\n",
    "\n",
    "train3.select(\"longitude\")\n",
    "    .describe()\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T21:31:00.451708Z",
     "start_time": "2021-01-22T21:30:59.988067Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|summary|          longitude|\n",
      "+-------+-------------------+\n",
      "|  count|              16510|\n",
      "|   mean|-119.56390490611753|\n",
      "| stddev| 2.0075057468016757|\n",
      "|    min|            -124.35|\n",
      "|    max|            -114.31|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "train4: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [longitude: double, latitude: double ... 8 more fields]\n",
       "test4: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [longitude: double, latitude: double ... 8 more fields]\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val Array(train4, test4) = housing\n",
    "    .randomSplit(Array(0.8, 0.2), 47)\n",
    "\n",
    "train4.select(\"longitude\")\n",
    "    .describe()\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T21:31:01.343060Z",
     "start_time": "2021-01-22T21:31:00.454521Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|summary|          longitude|\n",
      "+-------+-------------------+\n",
      "|  count|              16510|\n",
      "|   mean|-119.56390490611753|\n",
      "| stddev| 2.0075057468016757|\n",
      "|    min|            -124.35|\n",
      "|    max|            -114.31|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "train5: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [longitude: double, latitude: double]\n",
       "test5: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [longitude: double, latitude: double]\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val Array(train5, test5) = spark.read.format(\"csv\").option(\"header\",\"true\").option(\"inferSchema\",\"true\").load(\"housing.csv\")\n",
    "    .select(\"longitude\",\"latitude\")\n",
    "    .randomSplit(Array(0.8, 0.2), 47)\n",
    "\n",
    "train5.select(\"longitude\")\n",
    "    .describe()\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T21:31:02.085898Z",
     "start_time": "2021-01-22T21:31:01.345256Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|summary|          longitude|\n",
      "+-------+-------------------+\n",
      "|  count|              16510|\n",
      "|   mean|-119.56390490611753|\n",
      "| stddev| 2.0075057468016757|\n",
      "|    min|            -124.35|\n",
      "|    max|            -114.31|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "train6: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [longitude: double, latitude: double]\n",
       "test6: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [longitude: double, latitude: double]\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val Array(train6, test6) = spark.read.format(\"csv\").option(\"header\",\"true\").option(\"inferSchema\",\"true\").load(\"housing.csv\")\n",
    "    .select(\"longitude\",\"latitude\")\n",
    "    .randomSplit(Array(0.8, 0.2), 47)\n",
    "\n",
    "train6.select(\"longitude\")\n",
    "    .describe()\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting using hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T21:31:02.479239Z",
     "start_time": "2021-01-22T21:31:02.088138Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+------+----------+\n",
      "|longitude| id|bin_id|  crc32_id|\n",
      "+---------+---+------+----------+\n",
      "|  -122.23|  0|     0|4108050209|\n",
      "|  -122.22|  1|     1|2212294583|\n",
      "|  -122.24|  2|    10|2707236321|\n",
      "|  -122.25|  3|    11|3596227959|\n",
      "|  -122.25|  4|   100| 595022058|\n",
      "|  -122.25|  5|   101|1416650876|\n",
      "|  -122.25|  6|   110| 980181419|\n",
      "|  -122.25|  7|   111|1298878781|\n",
      "|  -122.26|  8|  1000|3022496535|\n",
      "|  -122.25|  9|  1001|3273692033|\n",
      "+---------+---+------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions._\n",
       "housing_new: org.apache.spark.sql.DataFrame = [longitude: double, latitude: double ... 11 more fields]\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "val housing_new = housing\n",
    "    .withColumn(\"id\",monotonicallyIncreasingId)\n",
    "    .withColumn(\"bin_id\", bin($\"id\"))\n",
    "    .withColumn(\"crc32_id\", crc32($\"bin_id\"))\n",
    "\n",
    "housing_new.select(\"longitude\",\"id\",\"bin_id\",\"crc32_id\")\n",
    "    .show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T21:31:02.898820Z",
     "start_time": "2021-01-22T21:31:02.480870Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "max_value: Long = 4294892987\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val max_value = housing_new.select(max($\"crc32_id\"))\n",
    "    .collect()(0)(0).asInstanceOf[Long]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T21:31:03.326816Z",
     "start_time": "2021-01-22T21:31:02.900752Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|summary|          longitude|\n",
      "+-------+-------------------+\n",
      "|  count|              16516|\n",
      "|   mean|-119.57123940421286|\n",
      "| stddev|  2.002698904521996|\n",
      "|    min|            -124.35|\n",
      "|    max|            -114.31|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "train7: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [longitude: double, latitude: double ... 11 more fields]\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val train7 = housing_new.where($\"crc32_id\" <= max_value*0.8)\n",
    "\n",
    "train7.select(\"longitude\")\n",
    "    .describe()\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T21:31:04.309849Z",
     "start_time": "2021-01-22T21:31:03.328391Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+---------------+------------------+--------------------+--------------------+\n",
      "|summary|          longitude|          latitude|housing_median_age|       total_rooms|    total_bedrooms|        population|        households|     median_income|median_house_value|ocean_proximity|                id|              bin_id|            crc32_id|\n",
      "+-------+-------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+---------------+------------------+--------------------+--------------------+\n",
      "|  count|               4124|              4124|              4124|              4124|              4099|              4124|              4124|              4124|              4124|           4124|              4124|                4124|                4124|\n",
      "|   mean|-119.56355722599397|35.629260426770095|28.547041707080503|2620.7082929194958| 533.3234935350085|1414.4544131910766|496.69495635305526|3.8649543161978688| 206447.7194471387|           null|10319.041222114452|2.499940458461118E13|3.8659915800725026E9|\n",
      "| stddev| 2.0070949654206958|2.1320818217337547|12.550783322001655|2181.2336367395937|415.42447349549246|1099.8751648377836|  379.189135202875|1.8810474208120014|115974.96019821496|           null| 5951.586701672246|3.847004028036372E13|2.4786910862792045E8|\n",
      "|    min|            -124.23|             32.56|               2.0|              12.0|               3.0|               8.0|               3.0|            0.4999|           26600.0|      <1H OCEAN|                 0|                   0|          3436709996|\n",
      "|    max|            -114.47|              41.8|              52.0|           39320.0|            6210.0|           16305.0|            5358.0|           15.0001|          500001.0|     NEAR OCEAN|             20630|       1111111111111|          4294892987|\n",
      "+-------+-------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+---------------+------------------+--------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "test7: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [longitude: double, latitude: double ... 11 more fields]\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val test7 = housing_new.where($\"crc32_id\" > max_value*0.8)\n",
    "test7.describe().show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
